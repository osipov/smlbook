{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77ZN-BAylPoU"
      },
      "source": [
        "# [Serverless Machine Learning in Action](https://www.manning.com/books/serverless-machine-learning-in-action?a_aid=osipov&a_bid=fa913283&)\n",
        "## by Carl Osipov"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HPLiT_xlliJ"
      },
      "source": [
        "Source Code for [Chapter 7](https://livebook.manning.com/book/serverless-machine-learning-in-action/chapter-7?a_aid=osipov&a_bid=fa913283&) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWyD1Bt9k26w"
      },
      "source": [
        "## <font color=red>Upload the `BUCKET_ID` file</font>\n",
        "\n",
        "Before proceeding, ensure that you have a backup copy of the `BUCKET_ID` file created in the [Chapter 2](https://colab.research.google.com/github/osipov/smlbook/blob/master/ch2.ipynb) notebook before proceeding. The contents of the `BUCKET_ID` file are reused later in this notebook and in the other notebooks.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwPOIYDdnXKN"
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "assert Path('BUCKET_ID').exists(), \"Place the BUCKET_ID file in the current directory before proceeding\"\n",
        "\n",
        "BUCKET_ID = Path('BUCKET_ID').read_text().strip()\n",
        "os.environ['BUCKET_ID'] = BUCKET_ID\n",
        "os.environ['BUCKET_ID']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ2rTEBfU20C"
      },
      "source": [
        "## **OPTIONAL:** Download and install AWS CLI\n",
        "\n",
        "This is unnecessary if you have already installed AWS CLI in a preceding notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei0Vm3p9UkT1"
      },
      "source": [
        "%%bash\n",
        "curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
        "unzip -o awscliv2.zip\n",
        "sudo ./aws/install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xoSKwf7U77e"
      },
      "source": [
        "## Specify AWS credentials\n",
        "\n",
        "Modify the contents of the next cell to specify your AWS credentials as strings. \n",
        "\n",
        "If you see the following exception:\n",
        "\n",
        "`TypeError: str expected, not NoneType`\n",
        "\n",
        "It means that you did not specify the credentials correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaRjFdSoT-q1"
      },
      "source": [
        "import os\n",
        "# *** REPLACE None in the next 2 lines with your AWS key values ***\n",
        "os.environ['AWS_ACCESS_KEY_ID'] = None\n",
        "os.environ['AWS_SECRET_ACCESS_KEY'] = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAMFo90AVJuI"
      },
      "source": [
        "## Confirm the credentials\n",
        "\n",
        "Run the next cell to validate your credentials."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZqAz5PjS_f1"
      },
      "source": [
        "%%bash\n",
        "aws sts get-caller-identity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66DsruTZWERS"
      },
      "source": [
        "If you have specified the correct credentials as values for the `AWS_ACCESS_KEY_ID` and the `AWS_SECRET_ACCESS_KEY` environment variables, then `aws sts get-caller-identity` used by the previous cell should have returned back the `UserId`, `Account` and the `Arn` for the credentials, resembling the following\n",
        "\n",
        "```\n",
        "{\n",
        "    \"UserId\": \"█████████████████████\",\n",
        "    \"Account\": \"████████████\",\n",
        "    \"Arn\": \"arn:aws:iam::████████████:user/█████████\"\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wywu4hC-WPxV"
      },
      "source": [
        "## Specify the region\n",
        "\n",
        "Replace the `None` in the next cell with your AWS region name, for example `us-west-2`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IowJTSN1e8B-"
      },
      "source": [
        "# *** REPLACE None in the next line with your AWS region ***\n",
        "os.environ['AWS_DEFAULT_REGION'] = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwJSUTvlfSE0"
      },
      "source": [
        "If you have specified the region correctly, the following cell should return back the region that you have specifies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CssvgRfUSu9"
      },
      "source": [
        "%%bash\n",
        "echo $AWS_DEFAULT_REGION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87N5zM7SA8bo"
      },
      "source": [
        "## Using ObjectStorageDataset\n",
        "\n",
        "\n",
        "`ObjectStorageDataset` provides support for tensor-based, out-of-memory datasets for the iterable-style `torch.utils.data.DataLoader` interface. The `ObjectStorageDataset` is not available by default when you install PyTorch, so you need to install it separately in your Python environment using:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdeYRTfyBCDE"
      },
      "source": [
        "!pip install kaen[osds]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYEobnJEBGTa"
      },
      "source": [
        "and once installed, import the class in your runtime and create an instance using:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByXQQ8hqEkFR"
      },
      "source": [
        "from kaen.torch import ObjectStorageDataset as osds\n",
        "BUCKET_ID = os.environ['BUCKET_ID']\n",
        "AWS_DEFAULT_REGION = os.environ['AWS_DEFAULT_REGION']\n",
        "\n",
        "BATCH_SIZE = 2 ** 20 # 1_048_576 \n",
        "\n",
        "train_ds = osds(f\"s3://dc-taxi-{BUCKET_ID}-{AWS_DEFAULT_REGION}/csv/dev/part*.csv\", \n",
        "                storage_options = {'anon': False},\n",
        "                batch_size = BATCH_SIZE)\n",
        "train_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5V_4JTGjqwP"
      },
      "source": [
        "The `shards_glob` parameter of the `ObjectStorageDataset` points to the metadata file about the CSV part files that match the `/csv/dev/part*.csv` glob. You can preview the metadata as a Pandas data frame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT8RAt1piEAS"
      },
      "source": [
        "import pandas as pd\n",
        "shards_df = pd.read_csv(f\"s3://dc-taxi-{BUCKET_ID}-{AWS_DEFAULT_REGION}/csv/dev/.meta/shards/*.csv\")\n",
        "print(shards_df[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "valsQoixFijy"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch = next(iter(DataLoader(train_ds)))\n",
        "\n",
        "batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4B29s74Fqpg"
      },
      "source": [
        "batch.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRREdltuslJp"
      },
      "source": [
        "batch.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U49NbWPyFsO5"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import torch as pt\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from kaen.torch import ObjectStorageDataset as osds\n",
        "\n",
        "pt.manual_seed(0);\n",
        "pt.set_default_dtype(pt.float64)\n",
        "\n",
        "BUCKET_ID = os.environ['BUCKET_ID']\n",
        "AWS_DEFAULT_REGION = os.environ['AWS_DEFAULT_REGION']\n",
        "\n",
        "BATCH_SIZE = 2 ** 20 #evaluates to 1_048_576\n",
        "train_ds = osds(f\"s3://dc-taxi-{BUCKET_ID}-{AWS_DEFAULT_REGION}/csv/dev/part*.csv\", \n",
        "                storage_options = {'anon': False},\n",
        "                batch_size = BATCH_SIZE)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=None)\n",
        "\n",
        "FEATURE_COUNT = 8\n",
        "\n",
        "w = pt.nn.init.kaiming_uniform_(pt.empty(FEATURE_COUNT, 1, requires_grad=True))\n",
        "b = pt.nn.init.kaiming_uniform_(pt.empty(1, 1, requires_grad = True))\n",
        "\n",
        "def batchToXy(batch):\n",
        "  batch = batch.squeeze_()  \n",
        "  return batch[:, 1:], batch[:, 0]\n",
        "\n",
        "def forward(X):\n",
        "  y_est = X @ w + b\n",
        "  return y_est.squeeze_()\n",
        "\n",
        "LEARNING_RATE = 0.03\n",
        "optimizer = pt.optim.SGD([w, b], lr = LEARNING_RATE)\n",
        "\n",
        "GRADIENT_NORM = .5\n",
        "\n",
        "ITERATION_COUNT = 50\n",
        "\n",
        "for iter_idx, batch in zip(range(ITERATION_COUNT), train_dl):\n",
        "  start_ts = time.perf_counter()\n",
        "\n",
        "  X, y = batchToXy(batch)\n",
        "\n",
        "  y_est = forward(X)\n",
        "  mse = pt.nn.functional.mse_loss(y_est, y)\n",
        "  mse.backward()\n",
        "\n",
        "  pt.nn.utils.clip_grad_norm_([w, b], GRADIENT_NORM) if GRADIENT_NORM else None\n",
        "\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  sec_iter = time.perf_counter() - start_ts\n",
        "\n",
        "  print(f\"Iteration: {iter_idx:03d}, Seconds/Iteration: {sec_iter:.3f} MSE: {mse.data.item():.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy7PSJjXLFcF"
      },
      "source": [
        "## Faster PyTorch tensor operations with Graphical Processing Units"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjtvOdWLLMaI"
      },
      "source": [
        "To find out exactly the number of CPU cores available to PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ObUE9pTLGq-"
      },
      "source": [
        "import os\n",
        "print(os.cpu_count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or7L3elLLTnf"
      },
      "source": [
        "In PyTorch it is customary to initialize the device variable as follows before using the GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0yL6-X3LKP6"
      },
      "source": [
        "device = pt.device(\"cuda\" if pt.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFBAs5j1Ld7w"
      },
      "source": [
        "To find out the number of ALUs you have available, you need to first use the `get_device_capability` method to find out your CUDA compute capability profile:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2_NcF0mLeO8"
      },
      "source": [
        "import torch as pt\n",
        "print([pt.cuda.get_device_properties(i) for i in range(pt.cuda.device_count())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB_qLOlLLtVw"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdVVXb_9MWDC"
      },
      "source": [
        "PyTorch defaults to using the CPU-based tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMHqdgo0MFUU"
      },
      "source": [
        "pt.set_default_dtype(pt.float64)\n",
        "\n",
        "tensor = pt.empty(1)\n",
        "print(tensor.dtype, tensor.device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJgih4OiMcSD"
      },
      "source": [
        "To specify the CUDA-based implementation as default you can use the `set_default_tensor_type` method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PicdqWqfMOch"
      },
      "source": [
        "pt.set_default_tensor_type(pt.cuda.FloatTensor)\n",
        "pt.set_default_dtype(pt.float64)\n",
        "\n",
        "tensor = pt.empty(1)\n",
        "print(tensor.dtype, tensor.device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAtZ3fcQM5u5"
      },
      "source": [
        "A better practice when using a GPU for tensor operations, is to create tensors directly on a desired device. Assuming that you initialize the `device` variable, you can create a tensor on a specific device by setting the `device` named parameter as shown here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRaP2VcjM0bs"
      },
      "source": [
        "device = pt.device(\"cuda\" if pt.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tensor = pt.empty(1, dtype=int, device=device)\n",
        "print(tensor.dtype, tensor.device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOFOgr1xNGgh"
      },
      "source": [
        "import timeit\n",
        "MAX_SIZE = 28\n",
        "\n",
        "def benchmark_cpu_gpu(n, sizes):\n",
        "  for device in [\"cpu\", \"cuda\"]:\n",
        "    for size in sizes:\n",
        "      a = pt.randn(size).to(device)\n",
        "      b = pt.randn(size).to(device)\n",
        "      yield timeit.timeit(lambda: a + b, number = n)\n",
        "\n",
        "sizes = [2 ** i for i in range(MAX_SIZE)]\n",
        "measurements = list(benchmark_cpu_gpu(1, sizes))\n",
        "cpu = measurements[:MAX_SIZE]\n",
        "gpu = measurements[MAX_SIZE:]\n",
        "ratios = [cpu[i] / gpu[i] for i in range(len(cpu))]\n",
        "ratios"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZo5jffVNSq_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rc('xtick', labelsize=20)\n",
        "plt.rc('ytick', labelsize=20)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot([2 ** i for i in range(MAX_SIZE)], ratios)\n",
        "plt.xscale(\"log\", basex=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SBtUE8eN-sN"
      },
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "plt.plot(sizes[:16], ratios[:16])\n",
        "plt.xscale(\"log\", basex=2);\n",
        "\n",
        "plt.rc('xtick', labelsize=20)\n",
        "plt.rc('ytick', labelsize=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INnKfnDHLAzV"
      },
      "source": [
        "## Scaling up to use GPU cores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8iVoMrtLAWX"
      },
      "source": [
        "import os\n",
        "import torch as pt\n",
        "from torch.utils.data import DataLoader\n",
        "from kaen.torch import ObjectStorageDataset as osds\n",
        "\n",
        "pt.manual_seed(0);\n",
        "pt.set_default_dtype(pt.float64)\n",
        "\n",
        "BATCH_SIZE = 1_048_576 # = 2 ** 20\n",
        "\n",
        "train_ds = osds(f\"s3://dc-taxi-{os.environ['BUCKET_ID']}-{os.environ['AWS_DEFAULT_REGION']}/csv/dev/part*.csv\", \n",
        "    storage_options = {'anon': False},\n",
        "    batch_size = BATCH_SIZE)\n",
        "  \n",
        "train_dl = DataLoader(train_ds, \n",
        "                      pin_memory = True) \n",
        "\n",
        "FEATURE_COUNT = 8\n",
        "\n",
        "w = pt.nn.init.kaiming_uniform_(pt.empty(FEATURE_COUNT, 1, requires_grad=True, device=device))\n",
        "b = pt.nn.init.kaiming_uniform_(pt.empty(1, 1, requires_grad = True, device=device))\n",
        "\n",
        "device = pt.device(\"cuda\" if pt.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def batchToXy(batch):\n",
        "  batch = batch.squeeze_().to(device)\n",
        "  return batch[:, 1:], batch[:, 0]\n",
        "\n",
        "def forward(X):\n",
        "  y_pred = X @ w + b\n",
        "  return y_pred.squeeze_()\n",
        "\n",
        "def loss(y_est, y):\n",
        "  mse_loss = pt.mean((y_est - y) ** 2)\n",
        "  return mse_loss\n",
        "\n",
        "LEARNING_RATE = 0.03\n",
        "optimizer = pt.optim.SGD([w, b], lr = LEARNING_RATE)\n",
        "\n",
        "GRADIENT_NORM = 0.5\n",
        "\n",
        "ITERATION_COUNT = 50\n",
        "\n",
        "for iter_idx, batch in zip(range(ITERATION_COUNT), train_dl):\n",
        "  start_ts = time.perf_counter()\n",
        "\n",
        "  X, y = batchToXy(batch)\n",
        "\n",
        "  y_est = forward(X)\n",
        "  mse = loss(y_est, y)\n",
        "  mse.backward()\n",
        "\n",
        "  pt.nn.utils.clip_grad_norm_([w, b], GRADIENT_NORM) if GRADIENT_NORM else None\n",
        "\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  sec_iter = time.perf_counter() - start_ts\n",
        "\n",
        "  print(f\"Iteration: {iter_idx:03d}, Seconds/Iteration: {sec_iter:.3f} MSE: {mse.data.item():.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYt-3VQUk5jv"
      },
      "source": [
        "Copyright 2021 CounterFactual.AI LLC. All Rights Reserved.\n",
        "\n",
        "Licensed under the GNU General Public License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. \n",
        "\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "https://github.com/osipov/smlbook/blob/master/LICENSE\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    }
  ]
}